# -------------------------------------------------------------------
# Telegram / MTProto configuration
# -------------------------------------------------------------------

# Telegram API ID issued by https://my.telegram.org (Telethon client uses it)
TG_API_ID=changeme
# Telegram API Hash paired with TG_API_ID for MTProto auth
TG_API_HASH=changeme

# -------------------------------------------------------------------
# Alert routing & digest preferences
# -------------------------------------------------------------------

# Where to deliver alerts: dm | channel | both
ALERT_MODE=both
# Target channel username or ID when ALERT_MODE includes channel delivery
ALERT_CHANNEL=changeme
# Enable hourly digest generation (true/false)
HOURLY_DIGEST=true
# Enable daily digest generation (true/false)
DAILY_DIGEST=true

# -------------------------------------------------------------------
# Redis connectivity
# -------------------------------------------------------------------

# Redis hostname reachable from both containers
REDIS_HOST=redis
# Redis TCP port
REDIS_PORT=6379
# Redis stream key storing processed Telegram messages
REDIS_STREAM=tgsentinel:messages
# Redis consumer group name for worker processing
REDIS_GROUP=workers
# Logical consumer ID inside the consumer group
REDIS_CONSUMER=worker-1

# -------------------------------------------------------------------
# Storage paths (dual-database contract)
# -------------------------------------------------------------------

# Sentinel worker application database URI
DB_URI=sqlite:////app/data/sentinel.db
# UI service database URI (UI-only state)
# Absolute path to Telethon session file (sentinel exclusive)
TG_SESSION_PATH=/app/data/tgsentinel.session

# -------------------------------------------------------------------
# Startup behavior
# -------------------------------------------------------------------

# Maximum seconds to wait for authentication before shutting down
# Set to 0 to wait indefinitely (recommended for production)
# Set to positive integer (e.g., 300) to timeout after that many seconds
SESSION_WAIT_SECS=0

# -------------------------------------------------------------------
# Sentinel API exposure
# -------------------------------------------------------------------

# Port where the sentinel Flask API listens
SENTINEL_API_PORT=8080
# Base URL the UI uses to reach sentinel APIs over Docker network
SENTINEL_API_BASE_URL=http://sentinel:8080/api

# -------------------------------------------------------------------
# Semantic scoring / embeddings
# -------------------------------------------------------------------

# Sentence-transformer model used for embeddings (empty disables)
EMBEDDINGS_MODEL=all-MiniLM-L6-v2

# Cosine similarity threshold for semantic matches
SIMILARITY_THRESHOLD=0.55

# Other models

# Recommended SIMILARITY_THRESHOLD
# SIMILARITY_THRESHOLD = 0.55
# - Balanced threshold for short/medium messages
# - High enough to reduce false positives
# - Low enough to capture meaningful semantic matches

# all-MiniLM-L6-v2
# - 384-dim lightweight encoder for fast CPU inference
# - Excellent balance of speed, size, and semantic quality
# - Ideal for clustering, search, and similarity at scale

# all-mpnet-base-v2
# - Higher semantic accuracy than MiniLM
# - 768-dim vectors with richer contextual encoding
# - Best for high-quality search, ranking, and similarity tasks

# bert-base-uncased
# - Classic BERT encoder, stable and well-established
# - Good general-purpose sentence embeddings
# - Heavier and slower, but reliable for baseline comparisons

# all-MiniLM-L12-v2
# - Larger MiniLM variant with improved embedding fidelity
# - Strong middle ground between speed and accuracy
# - Still CPU-friendly with higher semantic richness than L6

# multi-qa-mpnet-base-cos-v1
# - Retrieval-optimized variant of MPNet
# - Excellent for semantic search and QA-style ranking
# - Best when query-to-document matching matters

# paraphrase-MiniLM-L3-v2
# - Ultra-lightweight, extremely fast on CPU
# - Perfect for high-throughput or edge deployments
# - Prioritizes speed over deep semantic accuracy

# LaBSE
# - Multilingual embeddings for 100+ languages
# - Strong cross-lingual similarity and retrieval performance
# - Suitable for global, multilingual systems

# all-distilroberta-v1
# - Distilled RoBERTa with solid semantic performance
# - Strong English-only embeddings with moderate size
# - Good quality while remaining efficient

# sentence-t5-small
# - T5-based encoder with strong generalization ability
# - Great for semantic similarity and paraphrase tasks
# - More expressive than smaller MiniLM variants

# e5-small
# - Retrieval-tuned encoder, very CPU-efficient
# - Strong performer for ranking, search, and RAG workflows
# - Best “small” model in E5 lineup for cost-quality balance

# -------------------------------------------------------------------
# Runtime / logging
# -------------------------------------------------------------------

# Force unbuffered stdout/stderr for Docker logs
PYTHONUNBUFFERED=1
# Global log level for both services
LOG_LEVEL=INFO

# -------------------------------------------------------------------
# UI security & access control
# -------------------------------------------------------------------

# Flask secret key for sessions, CSRF, etc. (change in production)
UI_SECRET_KEY=2cecbcb9ed37253a7c608643ca1a898f19f173195561d11a4f10a6b5cf3380eb
# Optional UI lock password to guard the interface
UI_LOCK_PASSWORD=changeme
# Session idle timeout (seconds) before UI relock
UI_LOCK_TIMEOUT=900
# Uncomment to disable UI auth entirely (development only)
#UI_SKIP_AUTH=true

# -------------------------------------------------------------------
# Webhooks / admin operations
# -------------------------------------------------------------------

# Shared secret required by webhook integrations
WEBHOOK_SECRET_KEY=changeme
# Token protecting privileged sentinel admin endpoints
ADMIN_TOKEN=changeme

# -------------------------------------------------------------------
# Anomaly detection thresholds
# -------------------------------------------------------------------

# Multiplier applied to baseline message volume for anomaly detection
ANOMALY_VOLUME_THRESHOLD=4.0
# Multiplier applied to message importance scores
ANOMALY_IMPORTANCE_THRESHOLD=2.5
# Minimum alert rate (0-1) to trigger anomaly alerting
ANOMALY_ALERT_RATE=0.6
# Enable stddev-based anomaly mode (true/false)
ANOMALY_USE_STDDEV=true
# Stddev multiplier when ANOMALY_USE_STDDEV=true
ANOMALY_STDDEV_MULTIPLIER=2.5
